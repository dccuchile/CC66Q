{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qln4Tt9VEU2"
      },
      "source": [
        "# Tutorial 4: Tareas Supervisadas.\n",
        "\n",
        "\n",
        "### Cuerpo Docente\n",
        "\n",
        "- Profesores: [Andr√©s Abeliuk](https://aabeliuk.github.io/), [Fabi√°n Villena](https://villena.cl/).\n",
        "- Profesor Auxiliar: Mart√≠n Paredes\n",
        "\n",
        "\n",
        "### Objetivos del Tutorial\n",
        "\n",
        "- Motivaci√≥n y repaso de qu√© son los Word Embeddings.\n",
        "- Entrenar nuestros propios `word embeddings` usando un dataset con fuentes de noticias de diversos medios. üí™\n",
        "- Entrenar un modelo para predecir el medio correspondiente a cada noticia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8e-9vzuizLe"
      },
      "source": [
        "## **Repaso: Word Embedddings**\n",
        "\n",
        "Partamos por decir que una red neuronal no es m√°s que una serie de operaciones matem√°ticas sobre vectores con una gran cantidad de dimensiones (tensores). Por ende, si queremos entrenar un modelo necesitamos transformar el texto original a vectores num√©ricos.\n",
        "\n",
        "Una de las soluciones m√°s simples a este problema es la representaci√≥n de Bag of Words (BoW). Si aplicamos este m√©todo a cada palabra de cada documento, tendremos un vector one hot encoding por cada palabra. Esto quiere decir que tendremos vectores del largo del vocabulario $V$, con un 1 en la posici√≥n asociada a la palabra representada.\n",
        "\n",
        "Y estamos listos? Podemos entrenar redes neuronales?\n",
        "\n",
        "La verdad es que no es as√≠, y es que estamos ignorando un gran problema con este enfoque. üòû\n",
        "\n",
        "\n",
        "### El gran problema de Bag of Words\n",
        "\n",
        "Pensemos en estas 3 frases como documentos:\n",
        "\n",
        "- $doc_1$: `¬°Buen√≠sima la marraqueta!`\n",
        "- $doc_2$: `¬°Estuvo espectacular ese pan franc√©s!`\n",
        "- $doc_3$: `!Buen√≠sima esa pintura!`\n",
        "\n",
        "Sabemos $doc_1$ y $doc_2$ hablan de lo mismo üçûüçûüëå y que $doc_3$ üé® no tiene mucho que ver con los otros.\n",
        "\n",
        "Supongamos que queremos ver que tan similares son ambos documentos.\n",
        "Para esto, generamos un modelo `Bag of Words` sobre el documento, aplicando este m√©todo por cada palabra para luego tener la representaci√≥n final.\n",
        "\n",
        "\n",
        "Es decir, transformamos cada palabra a un vector one-hot y luego los sumamos por documento.\n",
        "\n",
        "Por simplicidad, omitiremos algunas stopwords y consideramos pan frances como un solo token. As√≠ nos quedar√≠a el siguiente vocabulario:\n",
        "\n",
        "$$v = \\{buen√≠sima, marraqueta, estuvo, espectacular, pan\\ franc√©s, pintura\\}$$\n",
        "\n",
        "Entonces, el $\\vec{doc_1}$ quedar√°:\n",
        "\n",
        "$$\\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\\\\ 0\\end{bmatrix} +\n",
        "  \\begin{bmatrix}0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0\\\\ 0\\end{bmatrix} =\n",
        "  \\begin{bmatrix}1 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0\\\\ 0\\end{bmatrix}$$\n",
        "\n",
        "El $\\vec{doc_2}$ quedar√°:\n",
        "\n",
        "$$\\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0\\\\ 0\\end{bmatrix} +\n",
        "  \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0\\\\ 0\\end{bmatrix} +\n",
        "  \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1\\\\ 0\\end{bmatrix} =\n",
        "  \\begin{bmatrix}0 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 1\\\\ 0\\end{bmatrix}$$\n",
        "\n",
        "Y el $\\vec{doc_3}$:\n",
        "\n",
        "$$\\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\\\\ 0\\end{bmatrix} +\n",
        "  \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\\\\ 1\\end{bmatrix} =\n",
        "  \\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0\\\\ 1\\end{bmatrix}$$\n",
        "\n",
        "\n",
        "\n",
        "**¬øCu√°l es el problema?**\n",
        "\n",
        "`buen√≠sima` $\\begin{bmatrix}1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\0\\end{bmatrix}$ y `espectacular` $ \\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0\\end{bmatrix}$ representan ideas muy similares. Por otra parte, sabemos que `marraqueta` $\\begin{bmatrix}0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\0\\end{bmatrix}$ y `pan franc√©s` $\\begin{bmatrix}0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\0\\end{bmatrix}$ se refieren al mismo objeto. Pero en este modelo, estos **son totalmente distintos**. Es decir, los vectores de las palabras que `buen√≠sima` y `espectacular` son tan distintas como `marraqueta` y `pan franc√©s`. Esto se debe a que cada palabra ocupa una dimensi√≥n distinta a las dem√°s y son completamente independientes. Esto evidentemente, repercute en la calidad de los modelos que creamos a partir de nuestro Bag of Words.\n",
        "\n",
        "![BoW](https://raw.githubusercontent.com/dccuchile/CC6205/master/tutorials/recursos/BoW-Problem.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlJ6GZe0eUNH"
      },
      "source": [
        "Ahora, si queremos ver que documento es mas similar a otro usando distancia euclidiana, veremos que:\n",
        "\n",
        "$$d(doc_1, doc_2) = 2.236$$\n",
        "$$d(doc_1, doc_3) = 1.414$$\n",
        "\n",
        "Es decir, $doc_1$ se parece mas a $doc_3$ aunque nosotros sabemos que $doc_1$ y $doc_2$ nos est√°n diciendo lo mismo!\n",
        "\n",
        "\n",
        "Nos gustar√≠a que eso no sucediera. Que existiera alg√∫n m√©todo que nos permitiera hacer que palabras similares tengan representaciones similares. Y que con estas, representemos mejor a los documentos, sin asumir que en el espacio son geom√©tricamente equidistantes, ya que esto no es verdad en la vida real.\n",
        "\n",
        "\n",
        "--------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxB0APe3S5b2"
      },
      "source": [
        "### **Word Embeddings**\n",
        "\n",
        "Es una de las representaciones m√°s populares del vocabulario de un corpus. La idea principal de los Word Embeddings es crear representaciones vectoriales densas y de baja dimensionalidad $(d << |V|)$ de las palabras a partir de su contexto.\n",
        "\n",
        "Volvamos a nuestro ejemplo anterior: `buen√≠sima` y `espectacular` ocurren muchas veces en el mismo contexto, por lo que los embeddings que los representan debiesen ser muy similares... (*ejemplos de mentira hechos a mano*):\n",
        "\n",
        "`buen√≠sima` $\\begin{bmatrix}0.32 \\\\ 0.44 \\\\ 0.92 \\\\ .001 \\end{bmatrix}$ y `espectacular` $\\begin{bmatrix}0.30 \\\\ 0.50 \\\\ 0.92 \\\\ .002 \\end{bmatrix}$ versus `marraqueta`  $\\begin{bmatrix}0.77 \\\\ 0.99 \\\\ 0.004 \\\\ .1 \\end{bmatrix}$ el cu√°l es claramente distinto.\n",
        "\n",
        "\n",
        "Pero, ¬øCu√°l es la utilidad de de crear estos vectores en NLP o en el √°rea de Machine Learning en general?\n",
        "\n",
        "Supongamos que tienen una enfermedad grave y deben ser operados el d√≠a de ma√±ana. Le dan a elegir entre ser operados por un estudiante de primer a√±o de medicina con algo de conocimiento m√©dico o bien ser operados por un ni√±o de 5 a√±os üë∂. ¬øA qui√©n elegir√≠as?\n",
        "\n",
        "Espero que tu opci√≥n haya sido el estudiante con una peque√±a noci√≥n de los t√©rminos m√©dicos implicados en una intervenci√≥n as√≠. Algo as√≠ es lo que se quiso lograr en el [paper](https://arxiv.org/abs/1301.3781) presentado por Mikolov en 2013, aludiendo a la herramienta **Word2Vec**. La idea es que si quieres resolver por ejemplo una tarea de clasificaci√≥n de texto, ¬øno ser√≠a √∫til utilizar el conocimiento de alg√∫n modelo pre-entrenado en una tarea similar de texto?. Claro, ser√≠a √∫til partir con los pesos entrenados por otra red, realizando lo que se llama **transfer learning**.\n",
        "\n",
        "Ya pero.. ¬øC√≥mo generamos estos vectores? ¬øC√≥mo podemos capturar el contexto? ¬øCu√°l ser√≠a esa task auxiliar a utilizar?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBGzM6DvGWTk"
      },
      "source": [
        "##### **Word2vec y Skip-gram**\n",
        "\n",
        "Word2Vec es probablemente el paquete de software mas famoso para crear word embeddings utilizando distintos modelos que emplean redes neuronales *shallow* o poco profundas.\n",
        "\n",
        "Este nos provee herramientas para crear distintos tipos de modelos, tales como `Skip-Gram` y `Continuous Bag of Word (CBOW)`. En este caso, solo veremos `Skip-Gram`.\n",
        "\n",
        "**Skip-gram** es una task auxiliar con la que crearemos nuestros embeddings. Esta tarea involucra tanto a las palabras y al contexto de ellas. Consiste en que por cada palabra del dataset, debemos predecir las palabras de su contexto (las palabras presentes en ventana de alg√∫n tama√±o $k$).\n",
        "\n",
        "![Overview](https://raw.githubusercontent.com/dccuchile/CC6205/master/tutorials/recursos/overview-skipgram.png)\n",
        "\n",
        "Para resolverla, usaremos una red de una sola capa oculta. Los pesos ya entrenados de esta capa ser√°n los que usaremos como embeddings.\n",
        "\n",
        "#### Detalles del Modelo\n",
        "\n",
        "- Como dijimos, el modelo ser√° una red de una sola capa. La capa oculta tendr√° una dimensi√≥n $d$ la cual nosotros determinaremos. Esta capa no tendr√° funci√≥n de activaci√≥n. Sin embargo, la de salida si, la cual ser√° una softmax para obtener las distribuciones de probabilidades y as√≠ ver cu√°les palabras pertenecen o no al contexto.\n",
        "\n",
        "- El vector de entrada, de tama√±o $|V|$, ser√° un vector one-hot de la palabra que estemos viendo en ese momento.\n",
        "\n",
        "- La salida, tambi√©n de tama√±o $|V|$, ser√° un vector que contenga la distribuci√≥n de probabilidad de que cada palabra del vocabulario pertenezca al contexto de la palabra de entrada.\n",
        "\n",
        "- Al entrenar, se comparar√° la distribuci√≥n de los contextos con la suma de los vectores one-hot del contexto real.\n",
        "\n",
        "\n",
        "(marraqueta, Estuvo), (marraqueta, buenisima), (marraqueta, la)\n",
        "![Skip Gram](https://raw.githubusercontent.com/dccuchile/CC6205/master/tutorials/recursos/Skip-gram.png)\n",
        "\n",
        "\n",
        "Nota: Esto es computacionalmente una locura. Por cada palabra de entrada, debemos calcular la probabilidad de aparici√≥n de todas las otras. Imaginen el caso de un vocabulario de 100.000 de palabras y de 10000000 oraciones...\n",
        "\n",
        "La soluci√≥n a esto es modificar la task a *Negative Sampling*. Esta transforma este problema de $|V|$ clases a uno binario.\n",
        "\n",
        "### La capa Oculta y los Embeddings\n",
        "\n",
        "Al terminar el entrenamiento, ¬øQu√© nos queda en la capa oculta?\n",
        "\n",
        "Una matriz de $v$ filas por $d$ columnas, la cual contiene lo que buscabamos: Una representaci√≥n continua de todas las palabras de nuestro vocabulario.  \n",
        "\n",
        "**Cada fila de la matriz es un vector que contiene la representaci√≥n continua una palabra del vocabulario.**\n",
        "\n",
        "\n",
        "<img src=\"http://mccormickml.com/assets/word2vec/word2vec_weight_matrix_lookup_table.png\" alt=\"Capa Oculta 1\" style=\"width: 400px;\"/>\n",
        "\n",
        "¬øC√≥mo la usamos eficientemente?\n",
        "\n",
        "Simple: usamos los mismos vectores one-hot de la entrada y las multiplicamos por la matriz:\n",
        "\n",
        "<img src=\"http://mccormickml.com/assets/word2vec/matrix_mult_w_one_hot.png\" alt=\"Skip Gram\" style=\"width: 400px;\"/>\n",
        "\n",
        "### Visualizaci√≥n\n",
        "\n",
        "Veamos c√≥mo se ven los embeddings de Word2Vec entrenados sobre un corpus gigante en Ingl√©s. Para facilitar el an√°lisis se reducen las 200 dimensiones a 3. El link a la visualizaci√≥n es el siguiente: Visualizaci√≥n: https://projector.tensorflow.org/\n",
        "\n",
        "### Espacio multidimensional\n",
        "\n",
        "Teniendo nuestro embeddings entonces podr√≠amos hacer operaciones tan interesantes como las siguientes:\n",
        "\n",
        "Manzana + P√∫rpura -> Ciruela\n",
        "\n",
        "Rey - Hombre + Mujer -> Reina\n",
        "\n",
        "Si bien no es posible obtener exactamente dichos vectores, esperar√≠amos que las palabras m√°s cercanas al vector resultante ser√≠an las entregadas, obteniendo as√≠ un significado de las palabras seg√∫n su contexto.\n",
        "\n",
        "\n",
        "### Fuentes\n",
        "\n",
        "Word2vec:\n",
        "- mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
        "- https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa\n",
        "\n",
        "Gensim:\n",
        "- https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial\n",
        "\n",
        "Nota: Las √∫ltimas 2 imagenes pertenecen a [Chris McCormick](http://mccormickml.com/about/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7cUyx_-SQHi"
      },
      "source": [
        "## **Repaso: Entrenar nuestros Embeddings**\n",
        "\n",
        "Para entrenar nuestros embeddings, usaremos el paquete gensim. Este trae una muy buena implementaci√≥n de `word2vec`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqqjpBZY1KT5",
        "outputId": "62896a1d-f29c-452b-d7f8-fed1f88ef4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WsA-mAO-SQHi"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from collections import defaultdict\n",
        "import string\n",
        "import multiprocessing\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "\n",
        "# word2vec\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
        "\n",
        "# scikit-learn\n",
        "import sklearn\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# visualizaciones\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from ipywidgets import widgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcbzFpYSSQHj"
      },
      "source": [
        "### Cargar el dataset y limpiar\n",
        "\n",
        "Utilizaremos un datos de diversas fuentes de noticias que cuenta con tres atributos principales:\n",
        "\n",
        "* texto: Referente al texto de la noticia.\n",
        "* medio: Referente al medio de la noticia.\n",
        "* fecha: Referente a la fecha de publicaci√≥n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G7tDAILPRDfi"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('https://raw.githubusercontent.com/giturra/JCC2023-WE/main/noticias_oct_dic_2019.tsv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "v6A2h_g4RWLh",
        "outputId": "21dda6a9-f6de-4425-e793-7a80cbce84e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               texto        medio  \\\n",
              "0  Rey de Tailandia despoja de t√≠tulos a su conso...  El Mercurio   \n",
              "1  Denuncian que personas con epilepsia sufrieron...  El Mercurio   \n",
              "2  √çndice victimizaci√≥n de hogares en el pa√≠s suf...  El Mercurio   \n",
              "3  Meditaci√≥n, cocina, jardiner√≠a, manualidades: ...  El Mercurio   \n",
              "4  Director de empresa que procesa datos electora...  El Mercurio   \n",
              "\n",
              "                 fecha  \n",
              "0  2019-10-21 14:51:00  \n",
              "1  2019-12-18 12:12:00  \n",
              "2  2019-10-15 09:58:00  \n",
              "3  2019-11-16 16:42:00  \n",
              "4  2019-11-01 05:25:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac873816-becf-4158-9b14-48650e74ba06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>medio</th>\n",
              "      <th>fecha</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rey de Tailandia despoja de t√≠tulos a su conso...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-10-21 14:51:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Denuncian que personas con epilepsia sufrieron...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-12-18 12:12:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√çndice victimizaci√≥n de hogares en el pa√≠s suf...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-10-15 09:58:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Meditaci√≥n, cocina, jardiner√≠a, manualidades: ...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-11-16 16:42:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Director de empresa que procesa datos electora...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-11-01 05:25:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac873816-becf-4158-9b14-48650e74ba06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac873816-becf-4158-9b14-48650e74ba06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac873816-becf-4158-9b14-48650e74ba06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-15bf8514-ba66-46bb-856d-9441e05b537d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15bf8514-ba66-46bb-856d-9441e05b537d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-15bf8514-ba66-46bb-856d-9441e05b537d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9997,\n        \"samples\": [\n          \"Realizar\\u00e1n olla com\\u00fan y cacerolazo este jueves en Chill\\u00e1n\\nPara este sexto d\\u00eda de manifestaciones de demandas sociales en la capital de \\u00d1uble han organizado dos actividades que esperan contar con una masiva participaci\\u00f3n como ha sido en los \\u00faltimos d\\u00edas.\\nLa primera convocatoria ser\\u00e1 a las 14:30 horas en la P\\u00e9rgola de la Plaza de Armas de Chill\\u00e1n, donde realizar\\u00e1n una olla com\\u00fan. \\u201cTrae tu plato y servicio y hablemos sobre nuestras demandas\\u201d, dice la invitaci\\u00f3n.\\nLuego, a las 17:00 horas, la explanada de la Intendencia de \\u00d1uble ser\\u00e1 el escenario para un\\u00a0cacerolazo en contra de \\u201clas propuestas que beneficia a empresarios\\u201d. La actividad tiene hora de t\\u00e9rmino a las 21:00.\\nLas masivas concentraciones de los \\u00faltimos d\\u00edas en Chill\\u00e1n se han estado caracterizado por un clima pac\\u00edfico, familiar y festivo.\\n\",\n          \"Video capta agresi\\u00f3n con bate contra inspector municipal\\nCarabineros de la Segunda Comisar\\u00eda de Chill\\u00e1n y el Ministerio P\\u00fablico\\u00a0ya tienen los antecedentes que les habr\\u00edan permitido identificar casi con total precisi\\u00f3n al autor de una\\u00a0violenta\\u00a0agresi\\u00f3n en contra de dos inspectores de la\\u00a0Municipalidad.\\nEl hombre, molesto porque le hab\\u00edan cursado una infracci\\u00f3n por estacionarse en un lugar no autorizado, en el sector del cruce Parque Lanta\\u00f1o, sac\\u00f3 un bate de b\\u00e9isbol desde la parte trasera de su auto y tras insultarlos, le lanz\\u00f3 un golpe al inspector Rolando Laubri\\u00e9, quien lo alcanz\\u00f3 a bloquear a costa de una severa contusi\\u00f3n en el codo y antebrazo derecho.\\nEste hecho, que adem\\u00e1s cont\\u00f3 con al menos una decena de testigos y qued\\u00f3 registrado en las c\\u00e1maras de televigilancia ubicada en el sector, se registr\\u00f3 pasadas\\u00a0las 21.50 horas de la noche del mi\\u00e9rcoles, luego que personal de\\u00a0Inspecci\\u00f3n Municipal acudiera a ese sector a solicitud de la\\u00a0Junta\\u00a0de\\u00a0Vecinos del Parque Lanta\\u00f1o, quienes denuncian que a causa de la gran cantidad de veh\\u00edculos mal estacionados en el cruce,\\u00a0\\u00a0tienen diversos problemas que van desde los atochamientos a las dificultades para el paso del cami\\u00f3n de la basura.\\n\\u201cLamentablemente, esta persona agredi\\u00f3 con el bate a uno de los inspectores, quien obviamente\\u00a0fue a constatar lesiones al hospital. Otro inspector tambi\\u00e9n sufri\\u00f3 una agresi\\u00f3n, pero de menor intensidad\\u201d, certific\\u00f3 Enrique Ch\\u00e1vez, encargado de la Oficina Municipal de Seguridad\\u00a0(OMSE).\\nCh\\u00e1vez, quien advirti\\u00f3\\u00a0que la unidad jur\\u00eddica municipal est\\u00e1 evaluando la opci\\u00f3n de querellarse contra el agresor, agreg\\u00f3\\u00a0que \\u201ces conocido que muchas veces los inspectores suelen ser agredidos tanto verbal como f\\u00edsicamente, aunque esto se ve m\\u00e1s en la zona del mercado por los problemas con los ambulantes; sin embargo, agresiones a inspectores que ven temas de tr\\u00e1nsito es m\\u00e1s inusual. Tenemos registradas unas cinco o seis en los \\u00faltimos cinco a\\u00f1os\\u201d.\\nDiscusi\\u00f3n preliminar\\nConforme a los antecedentes que se manejan en la OMSE,\\u00a0cuando los inspectores llegaron al punto de controversia, en primera instancia buscaron despejar el acceso dici\\u00e9ndole a las personas que estaban en sus autos que deb\\u00edan abandonar el lugar.\\nAdem\\u00e1s,\\u00a0ya hab\\u00edan comenzado una campa\\u00f1a en el vecindario advirtiendo que se comenzar\\u00eda a notificar a quienes perseveraran en esa irregularidad.\\n\\u201cSe\\u00a0dejaron las notificaciones en los autos que segu\\u00edan en el lugar. Fue en ese momento que la due\\u00f1a de un veh\\u00edculo Nissan, el que sale en el video, lleg\\u00f3 muy enojada y empez\\u00f3 a gritarle y a insultar a los inspectores. Ellos mantuvieron la calma, pero la se\\u00f1ora estaba fuera de s\\u00ed. Fue ah\\u00ed que llega este hombre, como de unos 30 a\\u00f1os, y lleg\\u00f3 s\\u00faper acelerado a gritar insultos y a empujar a todo el que se le pon\\u00eda por delante\\u201d, dijo uno de los inspectores,\\u00a0quien pidi\\u00f3 reserva de\\u00a0su\\u00a0identidad.\\nEl esc\\u00e1ndalo hizo que los dirigentes vecinales que estaban acompa\\u00f1ando a los funcionarios municipales se congregaran y, al menos uno o dos de ellos, intentaron calmar a los exaltados vecinos.\\n\\u201cPrimero entr\\u00f3 al auto e hizo como que hab\\u00eda sacado un arma. Por eso nosotros retrocedimos un poco, y ya despu\\u00e9s sac\\u00f3 el bate que med\\u00eda m\\u00e1s de un metro y medio y le lanz\\u00f3 el golpe al colega\\u201d, relat\\u00f3.\\nFinalmente, cuando el agresor se retiraba junto a la mujer en el Nissan, y tal como se aprecia en el video, se lanza en contra del mismo inspector que hab\\u00eda recibido el golpe con el bate, pero\\u00a0este lo alcanz\\u00f3 a esquivar.\\nLaubri\\u00e9 quedar\\u00e1 con licencia m\\u00e9dica hasta la pr\\u00f3xima semana.\\n\",\n          \"\\\"Black Friday\\\": diario deportivo fue acusado de racismo por pol\\u00e9mica portada\\nEl diario deportivo italiano Corriere dello Sport sac\\u00f3 este jueves una pol\\u00e9mica portada que gener\\u00f3 variados comentarios en la pen\\u00ednsula y que tuvo repercusi\\u00f3n en toda Europa.\\nEn un intento por participar el partido de este viernes entre Inter de Mil\\u00e1n y AS Roma, el matutino titul\\u00f3 en su portada \\\"Black Friday\\\" -en alusi\\u00f3n a las rebajas del comercio tras Acci\\u00f3n de Gracias- y utilizando im\\u00e1genes del delantero belga Romelu Lukaku y el defensor Chris Smalling, ambos a pr\\u00e9stamo desde Manchester United y cuyos pases est\\u00e1n en el mercado.\\nNo obstante, el \\\"juego de palabras\\\" no fue bien recibido y fue tildado de racista.\\nAnte la controversia generada sobre todo en redes sociales, el diario deportivo, uno de los m\\u00e1s tradicionales de Italia, se defendi\\u00f3 con un comunicado oficial, alegando mala intenci\\u00f3n por parte de la gente, argumentando que no se entendi\\u00f3 la idea de fondo.\\n\\\"Blanco, negro, amarillo. Negar la diferencia es el t\\u00edpico obst\\u00e1culo macrosc\\u00f3pico del racismo antirracista. El suburra mental de los moralistas dominicales, cuando el jueves es domingo tambi\\u00e9n. El 'Viernes Negro', para aquellos que lo quieren y pueden entender, fue y es solo el elogio de la diferencia, el orgullo de la diferencia, la magn\\u00edfica riqueza de la diferencia. Si no lo comprende, es porque no puede hacerlo o porque lo hace. Un t\\u00edtulo inocente, aunque perfectamente argumentado por Roberto Perrone, se transforma en veneno por quienes tienen el veneno dentro\\\", manifest\\u00f3 el diario.\\nM\\u00e1s de Liga italiana\\n20:09\\nLiga italiana\\nOlivier Giroud le dio el triunfo y la cima a AC Milan ante Napoli en Serie A\\n19:07\\nLiga italiana\\nMilan venci\\u00f3 a Napoli, super\\u00f3 a Inter y es l\\u00edder exclusivo en Italia\\n17:47\\nLiga italiana\\nMorata cort\\u00f3 su sequ\\u00eda para darle la victoria a Juventus\\nTemas\\n#Deportes\\n#F\\u00fatbol\\n#Fuera de Juego\\n#F\\u00fatbol\\n#Liga italiana\\n#Racismo\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"medio\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"The Clinic\",\n          \"Cooperativa CL\",\n          \"El Rancaguino\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fecha\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 9225,\n        \"samples\": [\n          \"2019-12-29 19:09:00\",\n          \"2019-10-04 12:00:00\",\n          \"2019-10-23 16:36:30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xEBQb14tSQHj"
      },
      "outputs": [],
      "source": [
        "# unir titulo con contenido de la noticia\n",
        "content = dataset['texto']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "gkG6dS9V476U",
        "outputId": "ddd9c8f0-a711-415e-bf5c-a54e7c1844c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Rey de Tailandia despoja de t√≠tulos a su conso...\n",
              "1    Denuncian que personas con epilepsia sufrieron...\n",
              "2    √çndice victimizaci√≥n de hogares en el pa√≠s suf...\n",
              "3    Meditaci√≥n, cocina, jardiner√≠a, manualidades: ...\n",
              "4    Director de empresa que procesa datos electora...\n",
              "Name: texto, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rey de Tailandia despoja de t√≠tulos a su conso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Denuncian que personas con epilepsia sufrieron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√çndice victimizaci√≥n de hogares en el pa√≠s suf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Meditaci√≥n, cocina, jardiner√≠a, manualidades: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Director de empresa que procesa datos electora...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "content.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8upF3fu-SQHk",
        "outputId": "76b0f9cd-f0e7-481c-b795-8e7ff5f1b086"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "content.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Y28NxiNySQHk",
        "outputId": "98adcaa7-525c-4ecd-b45f-c682bbe011ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1uvRtm_USQHk"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# limpiar puntuaciones y separar por tokens.\n",
        "punctuation = string.punctuation + \"¬´¬ª‚Äú‚Äù‚Äò‚Äô‚Ä¶‚Äî\"\n",
        "stopwords = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/Alir3z4/stop-words/master/spanish.txt'\n",
        ").values\n",
        "stopwords = Counter(stopwords.flatten().tolist())\n",
        "\n",
        "def simple_tokenizer(doc, lower=False):\n",
        "    if lower:\n",
        "        tokenized_doc = doc.translate(str.maketrans(\n",
        "            '', '', punctuation)).lower().split()\n",
        "\n",
        "    tokenized_doc = doc.translate(str.maketrans('', '', punctuation)).split()\n",
        "    tokenized_doc = [\n",
        "        token for token in tokenized_doc if token.lower() not in stopwords\n",
        "    ]\n",
        "    return tokenized_doc\n",
        "\n",
        "sentences = [simple_tokenizer(doc) for doc in content.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqH5QEmzSQHk",
        "outputId": "b81af28e-9a21-4700-d44b-405a66554603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de alguna noticia: ['Ley', 'Ciudadan√≠a', 'pol√©mica', 'norma', 'india', 'acusan', 'discriminatoria', 'provocado', 'oleada', 'protestas', 'semana', 'miles', 'personas', 'salido', 'a', 'manifestarse', 'semana', 'consecutiva', 'ciudades', 'India', 'mostrar', 'rechazo', 'Ley', 'Ciudadan√≠a', 'CAB', 'migrantes', 'auspiciada', 'Gobierno', 'jornadas', 'terminado', 'enfrentamiento', 'marchas', 'vuelto', 'violentas', 'registran', '15', 'muertes', 'relacionadas', 'hechos', 'Pero¬øpor', 'rechazo', 'amplio', 'a', 'ley', 'gubernamental', 'ley', 'Ciudadan√≠a', 'viene', 'a', 'reemplazar', 'a', 'norma', 'vigente', '64', 'a√±os', 'proh√≠be', 'migrantes', 'ilegales', 'pasen', 'a', 'ciudadanos', 'India', 'BBC', 'antigua', 'legislaci√≥n', 'ilegales', 'a', 'inmigrantes', 'ingresan', 'pa√≠s', 'pasaporte', 'vigente', 'documento', 'viaje', 'a', 'quedan', 'India', 'permitido', 'personas', 'deportadas', 'detenidas', 'ley', 'aprob√≥', '11', 'diciembre', 'anula', 'normativa', 'se√±ala', 'persona', 'vivir', 'Gobierno', 'federal', 'm√≠nimo', '11', 'a√±os', 'solicitar', 'ciudadan√≠a', 'exigir√°', 'm√≠nimo', 'a√±os', 'a', 'extranjeros', 'iniciar', 'proceso', 'optar', 'ciudadan√≠a', 'nacionalidad', 'Asimismo', 'ley', 'sostiene', 'personas', 'tarjeta', 'ciudadan√≠a', 'india', 'ultramar', '‚Äì', 'estatus', 'migratorio', 'permite', 'a', 'inmigrantes', 'origen', 'indio', 'vivir', 'indefinidamente', 'arriesguen', 'perderla', 'violan', 'leyes', 'locales', 'Reuters', 'Gobierno', 'expuso', 'ley', 'proseguida', 'registro', 'ciudadan√≠a', 'musulmanes', 'territorio', 'deber√°n', 'demostrar', 'residentes', 'originales', 'India', 'refugiados', 'vienen', 'Pakist√°n', 'Bangladesh', 'provocar', 'queden', 'ap√°tridas', 'ley', 'beneficiar√≠a', 'a', 'hind√∫es', 'cristianos', 'miembros', 'minor√≠as', 'religiosas', 'entraron', 'a', 'India', '2014', 'forma', 'irregular', 'demostrar', 'sufrieron', 'persecuci√≥n', 'religiosa', 'pa√≠ses', 'anteriormente', 'nombrados', 'rechazo', 'sentir', 'calles', 'd√≠as', 'punto', 'ley', 'grupos', 'opone', 'a', 'Ley', 'Ciudadan√≠a', 'sostiene', 'excluyente', 'viola', 'principios', 'seculares', 'estipulados', 'constituci√≥n', 'pa√≠s', 'se√±alan', 'fe', 'objeto', 'condici√≥n', 'acceder', 'a', 'ciudadan√≠a', 'Carta', 'Magna', 'India', 'proh√≠be', 'forma', 'discriminaci√≥n', 'religiosa', 'ciudadanos', 'garantiza', 'igualdad', 'personas', 'ley', 'a', 'tema', 'parlamentario', 'musulm√°n', 'Asaddudin', 'Owaisi', 'ley', 'peor', 'leyes', 'Hitler', 'conspiraci√≥n', 'convertir', 'a', 'musulmanes', 'ap√°tridas', 'Gautam', 'Bhatia', 'abogado', 'radicado', 'Delhi', 'dividir', 'a', 'inmigrantes', 'musulmanes', 'musulmanes', 'proyecto', 'ley', 'busca', 'expl√≠cita', 'descaradamente', 'consagrar', 'discriminaci√≥n', 'religiosa', 'ley', '√©tica', 'constitucional', 'secular', 'larga', 'data', 'Asimismo', 'historiador', 'Mukul', 'Kesavandijo', 'normativa', 'aparentemente', 'dirigida', 'a', 'extranjeros', 'objetivo', 'principal', 'deslegitimaci√≥n', 'ciudadan√≠a', 'musulmana', 'representantes', 'musulmanes', 'oposici√≥n', 'detallaron', 'ley', 'afecta', 'forma', 'directa', 'a', 'comunidad', '‚Äìque', '170', 'millones', 'adeptos', 'grupo', 'minoritario', 'India', '700', 'representantes', 'indios', 'incluidos', 'abogados', 'acad√©micos', 'actores', 'firmado', 'declaraci√≥n', 'reprueba', 'proyecto', 'ley', 'representaci√≥n', 'Gobierno', 'ministro', 'Interior', 'Amit', 'Shah', 'defendi√≥', 'ley', 'enfatizando', 'busca', 'ayudar', 'a', 'minor√≠as', 'perseguidas', 'pa√≠ses', 'vecinos', 'mayor√≠a', 'musulmana', 'quitando', 'ciudadan√≠a', 'a', 'musulmanes', 'India', 'asever√≥', 'Shah', 'proyecto', 'ley', 'otorgar', 'ciudadan√≠a', 'quitarla', 'Parlamento', 'aprob√≥', 'ley', 'semana', 'protestas', 'comenzaron', 'noreste', 'pa√≠s', 'sentimiento', 'antiinmigrante', 'localidades', 'exclusi√≥n', 'musulmanes', 'Tripura', 'Gobierno', 'despleg√≥', 'tropas', 'llevaron', 'refuerzos', 'a', 'Assam', 'ambas', 'zonas', 'fronterizas', 'Bangladesh', 'ciudadanos', 'mostrado', 'acuerdo', 'llegada', 'extranjeros', 'a', 'temen', 'llegada', 'migrantes', 'masa', 'aumente', 'competencia', 'tierras', 'altere', 'equilibrio', 'demogr√°fico', 'Assam', 'zona', 'afectada', 'manifestaciones', 'agosto', 'millones', 'personas', 'quedaron', 'afuera', 'registro', 'ciudadanos', 'autoridades', 'bloqueado', 'acceso', 'a', 'internet', '10', 'distritos', 'localidad', 'evitar', 'focos', 'violencia', 'Guwahati', 'declar√≥', 'toque', 'queda', 'violentos', 'enfrentamientos', 'fuerzas', 'policiales', 'manifestantes', 'd√≠a', 'informaci√≥n', 'oficial', 'recolectada', 'cifra', '15', 'muertos', 'producto', 'protestas']\n"
          ]
        }
      ],
      "source": [
        "print(\"Ejemplo de alguna noticia: {}\".format(sentences[14]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srh235fDSQHm"
      },
      "source": [
        "### Definir el modelo\n",
        "\n",
        "\n",
        "\n",
        "Primero, como es usual, creamos el modelo. En este caso, usaremos uno de los primero modelos de embeddings neuronales: `word2vec`\n",
        "\n",
        "Algunos par√°metros importantes:\n",
        "\n",
        "- `sentences`: Corresponde a una lista con la data para entrenar el modelo `word2vec`. En este caso a la lista tokenizada con el texto de las noticias.\n",
        "- `min_count`: Ignora todas las palabras que tengan frecuencia menor a la indicada.\n",
        "- `window` : Tama√±o de la ventana. Usaremos 4.\n",
        "- `size` : El tama√±o de los embeddings que crearemos. Por lo general, el rendimiento sube cuando se usan mas dimensiones, pero despu√©s de 300 ya no se nota cambio. Ahora, usaremos solo 200.\n",
        "- `workers`: Cantidad de CPU que ser√°n utilizadas en el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PxbhQixYSQHm"
      },
      "outputs": [],
      "source": [
        "w2v = Word2Vec(sentences= sentences,\n",
        "               min_count=10,\n",
        "                      window=4,\n",
        "                      vector_size=200,\n",
        "                      sample=6e-5,\n",
        "                      alpha=0.03,\n",
        "                      min_alpha=0.0007,\n",
        "                      negative=20,\n",
        "                      workers=multiprocessing.cpu_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pr80ooM6niL"
      },
      "source": [
        "### Entrenar el modelo\n",
        "\n",
        "Al definir el modelo de `Word2Vec` se construy√≥ el vocabulario y se entren√≥ el modelo para obtener los `word embeddings` de los textos. Sin embargo estos 2 pasos tambi√©n se pueden realizar de forma expl√≠cita para obtener un mayor control de los hiperpar√°metros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcoiPxJySQHn"
      },
      "source": [
        "#### Construir el vocabulario\n",
        "\n",
        "Para esto, se crear√° un conjunto que contendr√° (una sola vez) todas aquellas palabras que aparecen mas de `min_count` veces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8Gx_MtzeSQHn"
      },
      "outputs": [],
      "source": [
        "# w2v.build_vocab(sentences, progress_per=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGvA3Lr9SQHo"
      },
      "source": [
        "#### Entrenamiento\n",
        "\n",
        "A continuaci√≥n, entenaremos el modelo.\n",
        "Los par√°metros que usaremos ser√°n:\n",
        "\n",
        "- `total_examples`: N√∫mero de documentos.\n",
        "- `epochs`: N√∫mero de veces que se iterar√° sobre el corpus.\n",
        "\n",
        "Es recomendable que tengan instalado `cpython` antes de continuar. Aumenta bastante la velocidad de entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SXER4JiiSQHo",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "#t = time()\n",
        "#w2v.train(sentences, total_examples=w2v.corpus_count, epochs=5, report_delay=10)\n",
        "#print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMSGhv3XSQHo"
      },
      "source": [
        "Ahora que terminamos de entrenar el modelo, le indicamos que no lo entrenaremos mas.\n",
        "Esto nos permitir√° ejecutar eficientemente las tareas que realizaremos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PWbHUPjJSQHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee673879-7053-4713-bf1e-a98f76cf979a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2512947105.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  w2v.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        }
      ],
      "source": [
        "w2v.init_sims(replace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g47OlSg2SQHo"
      },
      "source": [
        "####  Guardar y cargar el modelo\n",
        "\n",
        "A su vez, para ahorrar tiempo, se pueden guardar y cargar modelos preentrenados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "hLd1DGPXSQHp",
        "outputId": "f2342a1c-01c3-4ed9-b00d-708888f6dce8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Si entrenaste el modelo y lo quieres guardar, descomentar el siguiente bloque.\\nif not os.path.exists(\\'./pretrained_models\\'):\\n    os.mkdir(\\'./pretrained_models\\')\\nw2v.save(\\'./pretrained_models/biobio_w2v.model\\')\\n\\n\\n# cargar el modelo (si es que lo entrenaron desde local.)\\nw2v = KeyedVectors.load(\"./pretrained_models/biobio_w2v.model\", mmap=\\'r\\')\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Si entrenaste el modelo y lo quieres guardar, descomentar el siguiente bloque.\n",
        "if not os.path.exists('./pretrained_models'):\n",
        "    os.mkdir('./pretrained_models')\n",
        "w2v.save('./pretrained_models/biobio_w2v.model')\n",
        "\n",
        "\n",
        "# cargar el modelo (si es que lo entrenaron desde local.)\n",
        "w2v = KeyedVectors.load(\"./pretrained_models/biobio_w2v.model\", mmap='r')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "hEvKTMmGSQHp",
        "outputId": "3033087a-7623-4f67-9556-2613b4114eba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# descargar el modelo desde github\\ndef read_model_from_github(url):\\n    if not os.path.exists(\\'./pretrained_models\\'):\\n        os.mkdir(\\'./pretrained_models\\')\\n\\n    r = requests.get(url)\\n    filename = url.split(\\'/\\')[-1]\\n    with open(\\'./pretrained_models/\\' + filename, \\'wb\\') as f:\\n        f.write(r.content)\\n    return True\\n\\n\\n[\\n    read_model_from_github(file) for file in [\\n        \\'https://github.com/dccuchile/CC6205/releases/download/Data/biobio_w2v.model\\',\\n    ]\\n]\\n# cargar el modelo (si es que lo entrenaron desde local.)\\nw2v = KeyedVectors.load(\"./pretrained_models/biobio_w2v.model\", mmap=\\'r\\')\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\"\"\"\n",
        "# descargar el modelo desde github\n",
        "def read_model_from_github(url):\n",
        "    if not os.path.exists('./pretrained_models'):\n",
        "        os.mkdir('./pretrained_models')\n",
        "\n",
        "    r = requests.get(url)\n",
        "    filename = url.split('/')[-1]\n",
        "    with open('./pretrained_models/' + filename, 'wb') as f:\n",
        "        f.write(r.content)\n",
        "    return True\n",
        "\n",
        "\n",
        "[\n",
        "    read_model_from_github(file) for file in [\n",
        "        'https://github.com/dccuchile/CC6205/releases/download/Data/biobio_w2v.model',\n",
        "    ]\n",
        "]\n",
        "# cargar el modelo (si es que lo entrenaron desde local.)\n",
        "w2v = KeyedVectors.load(\"./pretrained_models/biobio_w2v.model\", mmap='r')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3bDLWKpSQHu"
      },
      "source": [
        "## **Word Embeddings como caracter√≠sticas para clasificar**\n",
        "\n",
        "\n",
        "En esta secci√≥n, veremos como utilizar los word embeddings como caracter√≠stica para **clasificar noticias de diferentes medios**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wfdDcKHaHTeS"
      },
      "outputs": [],
      "source": [
        "def to_vector(tokens,model):\n",
        "    \"\"\" Receives a sentence string along with a word embedding model and\n",
        "    returns the vector representation of the sentence\"\"\"\n",
        "    vec = np.zeros(model.vectors.shape[1]) # creates an empty vector of 300 dimensions\n",
        "    for word in tokens: # iterates over the sentence\n",
        "        if word in model: # checks if the word is both in the word embedding and the tf-idf model\n",
        "            vec += model[word] # adds every word embedding to the vector\n",
        "    if np.linalg.norm(vec) > 0:\n",
        "        return vec / np.linalg.norm(vec) # divides the vector by their normal\n",
        "    else:\n",
        "        return vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['text_vector'] = dataset['texto'].apply(lambda x: to_vector(simple_tokenizer(x, lower=True), w2v.wv))\n",
        "display(dataset.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "LIb4gT1pU4Xb",
        "outputId": "d105cbf9-a3a4-4917-e9eb-66cab0d45182"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                               texto        medio  \\\n",
              "0  Rey de Tailandia despoja de t√≠tulos a su conso...  El Mercurio   \n",
              "1  Denuncian que personas con epilepsia sufrieron...  El Mercurio   \n",
              "2  √çndice victimizaci√≥n de hogares en el pa√≠s suf...  El Mercurio   \n",
              "3  Meditaci√≥n, cocina, jardiner√≠a, manualidades: ...  El Mercurio   \n",
              "4  Director de empresa que procesa datos electora...  El Mercurio   \n",
              "\n",
              "                 fecha                                        text_vector  \n",
              "0  2019-10-21 14:51:00  [0.12115625310623257, 0.07681214341510867, 0.0...  \n",
              "1  2019-12-18 12:12:00  [0.08605537242728246, 0.03853898140059818, 0.0...  \n",
              "2  2019-10-15 09:58:00  [0.10995108521931063, 0.0353733183089699, 0.08...  \n",
              "3  2019-11-16 16:42:00  [0.10471409251158333, 0.05582559056423561, 0.0...  \n",
              "4  2019-11-01 05:25:00  [0.08550749295611317, 0.06813306088471427, 0.0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a6c5488-c162-49a7-8d96-9d67b4243fd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto</th>\n",
              "      <th>medio</th>\n",
              "      <th>fecha</th>\n",
              "      <th>text_vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Rey de Tailandia despoja de t√≠tulos a su conso...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-10-21 14:51:00</td>\n",
              "      <td>[0.12115625310623257, 0.07681214341510867, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Denuncian que personas con epilepsia sufrieron...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-12-18 12:12:00</td>\n",
              "      <td>[0.08605537242728246, 0.03853898140059818, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>√çndice victimizaci√≥n de hogares en el pa√≠s suf...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-10-15 09:58:00</td>\n",
              "      <td>[0.10995108521931063, 0.0353733183089699, 0.08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Meditaci√≥n, cocina, jardiner√≠a, manualidades: ...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-11-16 16:42:00</td>\n",
              "      <td>[0.10471409251158333, 0.05582559056423561, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Director de empresa que procesa datos electora...</td>\n",
              "      <td>El Mercurio</td>\n",
              "      <td>2019-11-01 05:25:00</td>\n",
              "      <td>[0.08550749295611317, 0.06813306088471427, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a6c5488-c162-49a7-8d96-9d67b4243fd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a6c5488-c162-49a7-8d96-9d67b4243fd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a6c5488-c162-49a7-8d96-9d67b4243fd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ced81569-88ac-4170-9b2c-901a41d31afc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ced81569-88ac-4170-9b2c-901a41d31afc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ced81569-88ac-4170-9b2c-901a41d31afc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Denuncian que personas con epilepsia sufrieron ataques tras usar Twitter: Usuarios publicaron luces estrobosc\\u00f3picas\\nLa organizaci\\u00f3n Epilepsy Foundation, de origen estadounidense, present\\u00f3 una denuncia penal y solicit\\u00f3 una investigaci\\u00f3n a ra\\u00edz de que distintos usuarios de Twitter publicaran videos con \\\"luces intermitentes o estrobosc\\u00f3picas\\\" en noviembre, los cuales provocaron convulsiones a personas con epilepsia.;\\nLos usuarios de la plataforma utilizaron el hashtag de la fundaci\\u00f3n para atacar a las personas con epilepsia, de acuerdo a lo indicado.;\\n\\nLa directora de defensa legal, Allison Nichol manifest\\u00f3 a la BBC que \\\"estos ataques no son diferentes a una persona que lleva una luz estrobosc\\u00f3pica a una convenci\\u00f3n de personas con epilepsia y convulsiones, con la intenci\\u00f3n de inducir convulsiones y, por lo tanto, causar un da\\u00f1o significativo a los participantes\\\".\\n\\\"El hecho de que estos ataques ocurrieron durante el Mes Nacional de Concientizaci\\u00f3n sobre la Epilepsia solo resalta su naturaleza reprensible\\\", agreg\\u00f3. Adem\\u00e1s, la encargada en materia legal indic\\u00f3 que \\\"la fundaci\\u00f3n est\\u00e1 cooperando completamente con la polic\\u00eda y tiene la intenci\\u00f3n de utilizar todas las v\\u00edas disponibles para garantizar que los responsables respondan\\\"\\nDe acuerdo a los datos, cerca del 3% de las personas que sufren epilepsia tienen fotosensible, por lo que las \\\"luces intermitentes o estrobosc\\u00f3picas\\\" publicadas en la red social los afectar\\u00eda directamente.;\\nAnteriormente, la Sociedad de Epilepsia del Reino Unido dijo que se debe exigir a las compa\\u00f1\\u00edas de redes sociales que muestren advertencias.;\\n\",\n          \"Director de empresa que procesa datos electorales en Bolivia se\\u00f1ala que a\\u00fan no se sabe si hubo fraude\\nManuel Guzm\\u00e1n de Rojas, director general de Neotec, la empresa encargada de procesar los datos electorales en Bolivia, manifest\\u00f3 que, a pesar de que la compa\\u00f1\\u00eda realiz\\u00f3 su trabajo de forma transparente y que cumpli\\u00f3 con todos los procedimientos, a\\u00fan \\\"no se sabe con certeza si hubo o no fraude\\\".\\nGuzm\\u00e1n indic\\u00f3 que el trabajo desempe\\u00f1ado por la empresa es tan s\\u00f3lo una parte de todo el proceso, compuesto por varios componentes necesarios para llevar a cabo el recuento electoral.;\\nPor ello, destac\\u00f3 que se debe analizar todo el conjunto para poder determinar o descartar posibles irregularidades.\\n\\n\\\"Hay una fase anterior (al c\\u00f3mputo) que es el llenado de las actas, hacer que esa acta sea leg\\u00edtima, es un punto en el que hay que enfocarse, de ver que esas actas est\\u00e1n leg\\u00edtimamente ingresadas al sistema\\\", expres\\u00f3.\\nAs\\u00ed, afirm\\u00f3 que \\\"hay un segundo proceso que hay que verificar, que es si se hizo de acuerdo a ley\\\". Neotec indic\\u00f3 que ofrecer\\u00e1 toda la informaci\\u00f3n que se encuentra a su disposici\\u00f3n a la Organizaci\\u00f3n de los Estados Americanos (OEA) en el marco de la autor\\u00eda que est\\u00e1 llevando a cabo.\\n\\\"En este momento nadie puede decir de una manera convincente si hubo o no hubo fraude\\\", ha sostenido.\\n;\\nGuzm\\u00e1n se\\u00f1al\\u00f3 considerar que no hubo justificaci\\u00f3n t\\u00e9cnica alguna para suspender el trabajo del Sistema de Transmisi\\u00f3n de Resultados Electorales Preliminares (TREP) y que a pesar de ello los vocales del Tribunal Supremo Electoral (TSE) le ordenaron que se paralizara la labor. Se\\u00f1al\\u00f3 as\\u00ed que dicha determinaci\\u00f3n fue \\\"desastrosa\\\".\\nEn este sentido, cont\\u00f3 que tras la rueda de prensa en la que se presentaron los primeros resultados preliminares, la presidenta del TSE, Mar\\u00eda Eugenia Choque, le orden\\u00f3 paralizar el TREP y lo llam\\u00f3 a una reuni\\u00f3n de urgencia.\\n\\nLa presidenta del TSE dir\\u00eda horas despu\\u00e9s que la decisi\\u00f3n de paralizar el recuento se deb\\u00eda al intento de no generar confusi\\u00f3n con el c\\u00f3mputo oficial que estaban llevando a cabo los Tribunales Departamentales Electorales. Sin embargo, este no fue el motivo que se dio a la empresa Neotec.\\n\\\"En la reuni\\u00f3n exponen tres motivos: uno que hab\\u00eda un servidor extra\\u00f1o que no era extra\\u00f1o, pero era el que no deb\\u00eda ser usado, solamente era un servidor perimetral; dos, que cambiaron las tendencias de los resultados, lo cual era falso, les muestro que los resultados avanzaban de una forma lineal, que no hubo una inversi\\u00f3n y tres, que observan un tr\\u00e1fico inusual en la verificaci\\u00f3n de actas, pero hubo un tr\\u00e1fico elevado y era la hora normal\\\", ha relatado Guzm\\u00e1n.\\nSeg\\u00fan Guzm\\u00e1n, ninguna de las tres razones era v\\u00e1lida para paralizar el recuento.;\\n\\\"Despu\\u00e9s de dar la explicaci\\u00f3n a los vocales no hab\\u00eda motivos para suspender el TREP, sin embargo, ellos deciden suspenderlo hasta el d\\u00eda siguiente\\\", lament\\u00f3.\\n\",\n          \"\\u00cdndice victimizaci\\u00f3n de hogares en el pa\\u00eds sufre fuerte alza hasta un 40,6% y porcentaje de \\\"temor alto\\\" en familias casi se duplic\\u00f3\\nEl \\u00edndice de victimizaci\\u00f3n, que entrega la fundaci\\u00f3n Paz Ciudadana, sufri\\u00f3 una fuerte alza respecto de la medici\\u00f3n del a\\u00f1o pasado.\\nDe acuerdo al informe, el porcentaje de hogares en que uno o m\\u00e1s de sus integrantes fue v\\u00edctima de robo o intento de robo en los \\u00faltimos seis meses, alcanz\\u00f3 un 40,6%, subiendo 4,2 puntos en relaci\\u00f3n a 2018. Se trata del mayor nivel desde 2014, cuando este indicador se ubic\\u00f3 en 43,5% (ver gr\\u00e1fico m\\u00e1s abajo).\\n\\nEl porcentaje de hogares donde alg\\u00fan miembro de la familia ha sido v\\u00edctima es mayor en Santiago (45%), que en regiones (33,5%), diferencia que se acrecienta respecto al a\\u00f1o anterior (39,2% y 31,8%, respectivamente).\\nAdem\\u00e1s, el porcentaje de robos e intentos de robo que ocurre en la v\\u00eda p\\u00fablica se ha mantenido constante en los \\u00faltimos a\\u00f1os, con un 84,6%, sobre el 15,4% sufridos en el hogar en la medici\\u00f3n de 2019. Por su parte los robos cometidos con violencia se redujeron de un 27,8% a un 25,9 en el \\u00faltimo a\\u00f1o, aunque seg\\u00fan Paz Ciudadana, esta diferencia \\\"no es estad\\u00edsticamente significativa\\\".\\nEn otro \\u00edtem, el porcentaje de hogares revictimizados (afectados m\\u00e1s de 1 vez en el per\\u00edodo) se increment\\u00f3 4,5 puntos porcentuales frente a 2018, pasando de 21,5% a 26% en 2019. \\\"Este aumento se produce principalmente en la Regi\\u00f3n Metropolitana, donde la cifra creci\\u00f3 de 23,6% a 30,1%\\\", indic\\u00f3 el reporte.\\n\\n #contenedorgrafico  #graficoennoticia  div.header-grafico span  Miembro de la familia ha sido v\\u00edctima de robo o intento de robo(\\u00daltimos seis meses)\\n Fuente: \\u00cdndice Paz Ciudadana 2019\\n\\nEl reporte tambi\\u00e9n revel\\u00f3 de un incremento significativo del porcentajede familias que sienten un nivel de temor alto, llegando a un 19,6% de la muestra, siendo casi el doble del 10,4% del a\\u00f1o pasado. Esta alza se produjo tanto en Santiago como en regiones.\\n\\nAsimismo, el estudio mostr\\u00f3 que el porcentaje de familias que indicaron que cuando sufrieron un robo hicieron la denuncia disminuy\\u00f3 de forma importante en relaci\\u00f3n a 2018, pasando de un 61,3% a un 49,4%.\\nEste dato fue catalogado como \\\"preocupante\\\", debido que una menor cantidad de denuncias disminuye la informaci\\u00f3n disponible para realizar una persecuci\\u00f3n del delito.\\n\\\"Esto se relaciona con una baja calificaci\\u00f3n del servicio prestado por las instituciones que reciben la denuncia, particularmente Carabineros de Chile, cuya actuaci\\u00f3n fue catalogada como 'insatisfactoria' por el 53,5% de los encuestados, lo que representa un alza de 10,4 puntos porcentuales en comparaci\\u00f3n con 2018\\\", sostuvo el estudio.\\n\\nLa encuesta del 2019 evidencia una ca\\u00edda general en la calificaci\\u00f3n que los encuestados hacen de las instituciones dedicadas a la seguridad p\\u00fablica. No obstante, las mejor evaluadas corresponden a ambas polic\\u00edas alcanzando una nota 4,5 en el caso de la PDI y un 4,1 Carabineros.\\nEn el caso de las instituciones del sector justicia, los Fiscales del Ministerio P\\u00fablico y los jueces \\\"mostraron una leve alza no estad\\u00edsticamente significativa en su evaluaci\\u00f3n\\\", pasando de un 3,1 a un 3,2 y de un 3,0 a un 3,1, respectivamente.\\nMientras que Gendarmer\\u00eda de Chile tuvo una baja de 5 d\\u00e9cimas, pasando de una nota 4,4 en 2018 a un 3,9 este a\\u00f1o. Los alcaldes presentan una nota promedio de 4,1; mejorando en dos d\\u00e9cimas su evaluaci\\u00f3n en relaci\\u00f3n con lo registrado en el a\\u00f1o anterior.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"medio\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"El Mercurio\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fecha\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2019-12-18 12:12:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_vector\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD_A7ogRSQHw"
      },
      "source": [
        "### Dividir el dataset en training y test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "y3pOTi67SQHw"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataset.text_vector,\n",
        "                                                    dataset.medio,\n",
        "                                                    test_size=0.33,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Convert the Series of vectors into a NumPy array\n",
        "X_train = np.array(X_train.tolist())\n",
        "X_test = np.array(X_test.tolist())\n",
        "Y_train = np.array(y_train.tolist())\n",
        "Y_test = np.array(y_test.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento del clasificador"
      ],
      "metadata": {
        "id": "GxdP_06xZbhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = sklearn.linear_model.LogisticRegression(solver='liblinear')"
      ],
      "metadata": {
        "id": "6_1SGdblU0CV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(\n",
        "    X_train,\n",
        "    y_train\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "id": "IeZbvwm4Ww8o",
        "outputId": "0b8ce053-0515-4743-847c-754c6b538e6e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(solver='liblinear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "Bw-mrQ_pYEnR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b45e3fd9"
      },
      "source": [
        "### Matriz de confusi√≥n\n",
        "\n",
        "Como en cualquier problema de Machine Learning, la matriz de confusi√≥n es una herramienta fundamental para evaluar el rendimiento de un modelo de clasificaci√≥n. Nos muestra un resumen del n√∫mero de predicciones correctas e incorrectas, desglosadas por cada clase."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVOYpsuLX6zB",
        "outputId": "8bd217e4-5b1e-493a-8a7b-18d0803008d8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 75  20  17  37  50  23  14   3  55  21]\n",
            " [  8 240  20   7  15  11   6   2  12  14]\n",
            " [ 12  64  72  28  67  38  11   6  41   6]\n",
            " [ 14  42   8 135  91  10   4   1  17   1]\n",
            " [ 15  20  30  73 180  20   2   5   4   2]\n",
            " [ 21  36  55  33  52  56  22   5  31   8]\n",
            " [ 17  11  15  23  25  11  99   6  72  28]\n",
            " [ 16  85  19  17  36  25  30  56  38  10]\n",
            " [ 23  14  14  16  17  12  12   2 183  27]\n",
            " [ 16  19  24  15  25  10  20   3  48 173]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(\n",
        "    y_test,\n",
        "    y_pred\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWeiMY4KXUAL",
        "outputId": "8b41b728-82f9-444a-d3cd-a3ddecdb452d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "            CHV       0.35      0.24      0.28       315\n",
            " Cooperativa CL       0.44      0.72      0.54       335\n",
            "    El Mercurio       0.26      0.21      0.23       345\n",
            "  El Rancaguino       0.35      0.42      0.38       323\n",
            "   La Discusi√≥n       0.32      0.51      0.40       351\n",
            "      La Naci√≥n       0.26      0.18      0.21       319\n",
            "         La RED       0.45      0.32      0.38       307\n",
            "           MEGA       0.63      0.17      0.27       332\n",
            "Radio Concierto       0.37      0.57      0.45       320\n",
            "     The Clinic       0.60      0.49      0.54       353\n",
            "\n",
            "       accuracy                           0.38      3300\n",
            "      macro avg       0.40      0.38      0.37      3300\n",
            "   weighted avg       0.40      0.38      0.37      3300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de57fce2"
      },
      "source": [
        "### Clasificaci√≥n con  Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca1908d8",
        "outputId": "544b1c95-48d3-4217-a1c1-0913f37ec655"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_classifier = SVC()\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix for SVM:\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "\n",
        "print(\"\\nClassification Report for SVM:\")\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for SVM:\n",
            "[[ 91  19  24  33  40  41  15   2  40  10]\n",
            " [ 10 234  21   9  13  16   5   2  12  13]\n",
            " [ 16  57  79  24  63  59  22   1  20   4]\n",
            " [ 17  26   6 118 105  21  16   1  12   1]\n",
            " [ 17  18  31  53 186  25  14   4   1   2]\n",
            " [ 30  29  58  28  44  79  20   1  24   6]\n",
            " [ 18   9  13  20  19  20 146   0  53   9]\n",
            " [ 21  75  19  15  29  43  13  75  33   9]\n",
            " [ 43   6  11  10  12  24  14   2 175  23]\n",
            " [ 38  16  23  16  20  25  19   1  29 166]]\n",
            "\n",
            "Classification Report for SVM:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "            CHV       0.30      0.29      0.30       315\n",
            " Cooperativa CL       0.48      0.70      0.57       335\n",
            "    El Mercurio       0.28      0.23      0.25       345\n",
            "  El Rancaguino       0.36      0.37      0.36       323\n",
            "   La Discusi√≥n       0.35      0.53      0.42       351\n",
            "      La Naci√≥n       0.22      0.25      0.24       319\n",
            "         La RED       0.51      0.48      0.49       307\n",
            "           MEGA       0.84      0.23      0.36       332\n",
            "Radio Concierto       0.44      0.55      0.49       320\n",
            "     The Clinic       0.68      0.47      0.56       353\n",
            "\n",
            "       accuracy                           0.41      3300\n",
            "      macro avg       0.45      0.41      0.40      3300\n",
            "   weighted avg       0.45      0.41      0.40      3300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b22fefd8"
      },
      "source": [
        "### Clasificaci√≥n Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aae0de5",
        "outputId": "4d7accb1-802c-47b6-ef63-b9467a69e492"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "print(\"Confusion Matrix for Random Forest:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "\n",
        "print(\"\\nClassification Report for Random Forest:\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Random Forest:\n",
            "[[110  13  27  29  21  34   8  12  36  25]\n",
            " [ 19 230  24   7   5  15   6   8  10  11]\n",
            " [ 18  30 106  26  42  49  26  13  24  11]\n",
            " [ 13   9   7 178  61  24  20   0   9   2]\n",
            " [ 16   6  33  83 156  33   7   4   4   9]\n",
            " [ 38  14  65  24  32  78  17  13  24  14]\n",
            " [ 12   5  14  13  13  13 177   7  40  13]\n",
            " [ 17  33  16   8   8  22  12 183  23  10]\n",
            " [ 38   7   8  12  13  10  20   5 170  37]\n",
            " [ 46  10  21   8  14  22  11   4  25 192]]\n",
            "\n",
            "Classification Report for Random Forest:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "            CHV       0.34      0.35      0.34       315\n",
            " Cooperativa CL       0.64      0.69      0.66       335\n",
            "    El Mercurio       0.33      0.31      0.32       345\n",
            "  El Rancaguino       0.46      0.55      0.50       323\n",
            "   La Discusi√≥n       0.43      0.44      0.44       351\n",
            "      La Naci√≥n       0.26      0.24      0.25       319\n",
            "         La RED       0.58      0.58      0.58       307\n",
            "           MEGA       0.73      0.55      0.63       332\n",
            "Radio Concierto       0.47      0.53      0.50       320\n",
            "     The Clinic       0.59      0.54      0.57       353\n",
            "\n",
            "       accuracy                           0.48      3300\n",
            "      macro avg       0.48      0.48      0.48      3300\n",
            "   weighted avg       0.48      0.48      0.48      3300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizando un pipeline\n",
        "\n",
        "Tambi√©n, todo lo realizado anteriormente se puede definir en un pipeline."
      ],
      "metadata": {
        "id": "uhoIIS4vasrM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNtnEzWMSQHw"
      },
      "source": [
        "Primero, crearemos el Transformer con el cual convertiremos el documento a vector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spUfFXrNSQHw"
      },
      "source": [
        "### Doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IXq9b_pYSQHw"
      },
      "outputs": [],
      "source": [
        "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transforma Noticias a representaciones vectoriales usando alg√∫n modelo de Word Embeddings.\n",
        "    Recibe un modelo de Word Embeddings y una funci√≥n de agregaci√≥n. Esta √∫ltima ser√° necesaria\n",
        "    para posteriormente representar el documento para un problema a resolver\n",
        "    (como en este caso de clasificaci√≥n).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, aggregation_func):\n",
        "        # extraemos los embeddings desde el objeto contenedor. ojo con esta parte.\n",
        "        self.model = model.wv\n",
        "\n",
        "        # indicamos la funci√≥n de agregaci√≥n (np.min, np.max, np.mean, np.sum, ...)\n",
        "        self.aggregation_func = aggregation_func\n",
        "\n",
        "    def simple_tokenizer(self, doc, lower=False):\n",
        "        \"\"\"Tokenizador. Elimina signos de puntuaci√≥n, lleva las letras a min√∫scula(opcional) y\n",
        "           separa el Noticias por espacios.\n",
        "        \"\"\"\n",
        "        if lower:\n",
        "            doc.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
        "        return doc.translate(str.maketrans('', '', string.punctuation)).split()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "\n",
        "        doc_embeddings = []\n",
        "\n",
        "        for doc in X:\n",
        "            # tokenizamos el documento. Se llevan todos los tokens a min√∫scula.\n",
        "            # ojo con esto, ya que puede que tokens con min√∫scula y may√∫scula tengan\n",
        "            # distintas representaciones\n",
        "            tokens = self.simple_tokenizer(doc, lower = True)\n",
        "\n",
        "            selected_wv = []\n",
        "            for token in tokens:\n",
        "                if token in self.model.index_to_key:\n",
        "                    selected_wv.append(self.model[token])\n",
        "\n",
        "            # si seleccionamos por lo menos un embedding para el tweet, lo agregamos y luego lo a√±adimos.\n",
        "            if len(selected_wv) > 0:\n",
        "                doc_embedding = self.aggregation_func(np.array(selected_wv), axis=0)\n",
        "                doc_embeddings.append(doc_embedding)\n",
        "            # si no, a√±adimos un vector de ceros que represente a ese documento.\n",
        "            else:\n",
        "                print('No pude encontrar ning√∫n embedding en el tweet: {}. Agregando vector de ceros.'.format(doc))\n",
        "                doc_embeddings.append(np.zeros(self.model.vector_size)) # la dimension del modelo\n",
        "\n",
        "        return np.array(doc_embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3NG6AvpSQHw"
      },
      "source": [
        "### Definimos el pipeline\n",
        "\n",
        "\n",
        "Usaremos la transformaci√≥n que creamos antes mas una regresi√≥n log√≠stica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eBjMxandSQHx"
      },
      "outputs": [],
      "source": [
        "clf = LogisticRegression(max_iter=10)\n",
        "\n",
        "doc2vec_mean = Doc2VecTransformer(w2v, np.mean)\n",
        "doc2vec_sum = Doc2VecTransformer(w2v, np.sum)\n",
        "doc2vec_max = Doc2VecTransformer(w2v, np.max)\n",
        "\n",
        "\n",
        "pipeline = Pipeline([('doc2vec', doc2vec_sum), ('clf', clf)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buMnvsO8SQHx"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfiGZpotSQHx"
      },
      "source": [
        "**Predecimos y evaluamos:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4R7zhgqSQHx"
      },
      "outputs": [],
      "source": [
        "y_pred = pipeline.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKEU3QgBSQHx"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCBjfMFBSQHx",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdTu7vzmSQHy"
      },
      "outputs": [],
      "source": [
        "pipeline.predict(\n",
        "    [(\"Alguna noticia..\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBlia-JJSQHy"
      },
      "source": [
        "## **Usandolo con BoW**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLBZbmSShn17"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dataset.texto,\n",
        "                                                    dataset.medio,\n",
        "                                                    test_size=0.33,\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ6IO16JSQHy"
      },
      "outputs": [],
      "source": [
        "# Definimos el vectorizador para convertir el texto a BoW:\n",
        "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
        "\n",
        "# Definimos el clasificador que usaremos.\n",
        "clf_2 = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Definimos el pipeline\n",
        "pipeline_2 = Pipeline([('features',\n",
        "                        FeatureUnion([('bow', CountVectorizer()),\n",
        "                                      ('doc2vec', doc2vec_sum)])), ('clf', clf)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnTlbg6FSQHy"
      },
      "outputs": [],
      "source": [
        "pipeline_2.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVL6-TGWSQHy"
      },
      "outputs": [],
      "source": [
        "y_pred_2 = pipeline_2.predict(X_test)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_2)\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XILZeUSwSQHy"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred_2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}