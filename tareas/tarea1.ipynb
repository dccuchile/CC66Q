{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iW239eziMR7"
      },
      "source": [
        "# Tarea 1\n",
        "\n",
        "### Cuerpo Docente\n",
        "\n",
        "- Profesores: [Andrés Abeliuk](https://aabeliuk.github.io/), [Fabián Villena](https://villena.cl/).\n",
        "- Profesor Auxiliar: Martín Paredes\n",
        "\n",
        "### Instrucciones generales\n",
        "\n",
        "- Grupos de máximo 4 personas.\n",
        "- Esta prohibido compartir las respuestas con otros grupos.\n",
        "- Indicios de copia serán penalizados con la nota mínima.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente serán respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente, si utiliza material extra debe citarlo.\n",
        "\n",
        "\n",
        "### Integrantes\n",
        "\n",
        "> POR FAVOR AGREGAR TODOS LOS NOMBRES DE LOS INTEGRANTES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvRYIoMgiiNn"
      },
      "source": [
        "# Preguntas Teoricas\n",
        "\n",
        "1. ¿Por qué es importante realizar un preprocesamiento adecuado antes de aplicar modelos de aprendizaje automático en NLP?\n",
        "  - *Respuesta*\n",
        "\n",
        "2. Imagina que trabajas con un corpus grande y sin limpiar (por ejemplo, tweets). ¿Qué pasos adicionales incluirías en el preprocesamiento para mejorar la calidad del análisis?\n",
        "  - *Respuesta*\n",
        "\n",
        "3. Explica brevemente la diferencia entre lematización y stemming.\n",
        "  - *Respuesta*\n",
        "\n",
        "4. Si una palabra aparece con mucha frecuencia en un corpus, ¿crees que siempre es relevante? Justifica tu respuesta.\n",
        "  - *Respuesta*\n",
        "\n",
        "5. Explica la principal diferencia entre las representaciones Bag of Words y TF-IDF.\n",
        "  - *Respuesta*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iljXpaTrLSsG"
      },
      "source": [
        "# Parte Práctica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HLEsoDKj5zM"
      },
      "source": [
        "## Pregunta 1\n",
        "En muchas ocasiones, las bibliotecas necesitan inventariar la información de todos los libros disponibles en su stock. Dado que la información puede estar sin procesar o contener errores, se te solicita, en tu calidad de estudiante del módulo de Procesamiento del Lenguaje Natural (NLP), que revises la información contenida en el archivo libros.txt.\n",
        "\n",
        "Para revisar la información debe realizar los siguientes pasos usando sólo funciones nativas de Python:\n",
        "\n",
        "- Leer el Archivo: Abrir el archivo libros.txt y leer su contenido.\n",
        "- Transformación de Strings: Convertir los títulos de los libros y los nombres de los autores a mayúsculas.\n",
        "- Búsqueda de Strings: Encontrar y mostrar todos los libros que contienen la palabra 'la' en el título.\n",
        "- Split de Strings: Para cada autor, extraer y mostrar solo su primer nombre.\n",
        "- Longitud de Strings: Calcular y mostrar la cantidad de palabras en el título de cada libro."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L -o /content/libros.txt https://raw.githubusercontent.com/dccuchile/CC66Q/main/tareas/data/libros.txt #Obtener libros.txt\n"
      ],
      "metadata": {
        "id": "1Z0VgHl8bRnq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca58e3dc-fa0b-4140-88dc-5bf6ad352068"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   821  100   821    0     0   3514      0 --:--:-- --:--:-- --:--:--  3523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-ruh7qpMvsI"
      },
      "source": [
        "## Pregunta 2\n",
        "\n",
        " a) Diseñe una función **`get_vocab()`** que extraiga los tokens de este corpus solamente tokenizando.\n",
        " dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]\n",
        "``\n",
        "``\n",
        "\n",
        "***Resultado esperado***:\n",
        "<table>\n",
        "    <tr>\n",
        "        <td>['favorite',\n",
        " 'Spanish',\n",
        " 'language',\n",
        " 'I',\n",
        " 'like',\n",
        " 'programming',\n",
        " 'languages',\n",
        " 'my',\n",
        " 'human',\n",
        " 'is'] </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "``\n",
        "``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Nr6Ig3yvwWEH"
      },
      "outputs": [],
      "source": [
        "dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "NUczCQ1kMvHS"
      },
      "outputs": [],
      "source": [
        "def get_vocab(dataset):\n",
        "  ### Aquí inicia tu código ###\n",
        "\n",
        "  ...\n",
        "\n",
        "  ### Aquí termina tu código ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPSLm_LDOu6o"
      },
      "source": [
        "b) 4 - WorldCloud - Seleccione un corpus de texto de la librería **`nltk`**, y cree un word cloud de las principales palabras. Para esto corra la siguiente línea y elija un corpus.\n",
        "\n",
        "De acuerdo, a los resultados obtenidos, considera que el WorldCloud refleja el contenido principal del que habla un documento, si es así ¿Porqué?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bDuI6a-3OvDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98df9b3-2087-4ebb-b9e1-38c9648d131c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "#Por ejemplo\n",
        "import nltk\n",
        "nltk.download('gutenberg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBIKUH4tiMSH"
      },
      "source": [
        "## Pregunta 3\n",
        "### Contexto\n",
        "\n",
        "El discurso de odio es cualquier expresión que promueva o incite a la discriminación, la hostilidad o la violencia hacia una persona o grupo de personas en una relación asimétrica de poder, tal como la raza, la etnia, el género, la orientación sexual, la religión, la nacionalidad, una discapacidad u otra característica similar.\n",
        "\n",
        "En cambio, la incivilidad se refiere a cualquier comportamiento o actitud que rompe las normas de respeto, cortesía y consideración en la interacción entre personas. Esta puede manifestarse de diversas formas, tal como insultos, ataques personales, sarcasmo, desprecio, entre otras.\n",
        "\n",
        "En esta tarea tendrán a su disposición un dataset de textos con las etiquetas `odio`, `incivilidad` o `normal`. La mayor parte de los datos se encuentra en español de Chile. Con estos datos, deberán entrenar un modelo que sea capaz de predecir la etiqueta de un texto dado.\n",
        "\n",
        "El corpus para esta tarea se compone de 3 datasets:  \n",
        "- [Multilingual Resources for Offensive Language Detection de Arango et al. (2022)](https://aclanthology.org/2022.woah-1.pdf#page=136)\n",
        "- [Dataton UTFSM No To Hate (2022)](http://dataton.inf.utfsm.cl/)\n",
        "- Datos generados usando la [API de GPT3 (modelo DaVinci 03)](https://platform.openai.com/docs/models/gpt-3).\n",
        "\n",
        "Agradecimientos a los autores por compartir los datos y a David Miranda, Fabián Diaz, Santiago Maass y Jorge Ortiz por revisar y reetiquetar los datos en el contexto del curso \"Taller de Desarrollo de Proyectos de IA\" (CC6409), Departamento de Ciencias de la Computación, Universidad de Chile.\n",
        "\n",
        "Los datos solo pueden ser usados con fines de investigación y docencia. Está prohibida la difusión externa.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZjrxFD2iMSI"
      },
      "source": [
        "#### Para el siguiente informe deben:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcwwfIjriMSJ"
      },
      "source": [
        "Para la siguente tarea deberá revolver una tarea de multi-clasificación, realizando los siguentes pasos:\n",
        "\n",
        "- Realizar un análisis estadístico del corpus.\n",
        "- Crear dos tipos de text representation.\n",
        "- Desarrollar al menos cuatros tipos de clasificadores que resuelvan la tarea.\n",
        "- Análizar sus resultados.\n",
        "\n",
        "Sin embargo, primero cargaremos el datataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DkPVO6ESiMSK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvB2UE62iMSM"
      },
      "source": [
        "### Cargar dataset\n",
        "\n",
        "En esta sección, cargaremos el dataset desde el repositorio del módulo. Para ello ejecute las siguientes líneas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "8rSTfQ2AiMSM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "pFJiPdc9iMSO"
      },
      "outputs": [],
      "source": [
        "# Dataset de entrenamiento.\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/new/assignment_1/train/train.tsv\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtg92w0iiMSP"
      },
      "source": [
        "### Analizar los datos\n",
        "\n",
        "En esta sección analizaremos el balance de los datos. Para ello se imprime la cantidad de tweets de cada dataset agrupados por la intensidad de sentimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Hi7mS3yViMSQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "df79948b-0d44-4dba-ee18-9c402d4b8500"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                              texto        clase\n",
              "9045  6412  @user Tengo un plan!\\n\\nLimpiate el poto con f...       normal\n",
              "5206  2654  @user Iba a comentar que la frase original era...  incivilidad\n",
              "7157  7643  @user Dejen de darle tribuna a este comunacho!...  incivilidad\n",
              "1294  4478  @user Boric cállate un rato. Por el amor de Di...  incivilidad\n",
              "5469  5617  @user @user @user @user @user Ese conchetumare...  incivilidad"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5696d1f4-6b10-4010-90bf-b69c5e115673\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>texto</th>\n",
              "      <th>clase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9045</th>\n",
              "      <td>6412</td>\n",
              "      <td>@user Tengo un plan!\\n\\nLimpiate el poto con f...</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5206</th>\n",
              "      <td>2654</td>\n",
              "      <td>@user Iba a comentar que la frase original era...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7157</th>\n",
              "      <td>7643</td>\n",
              "      <td>@user Dejen de darle tribuna a este comunacho!...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>4478</td>\n",
              "      <td>@user Boric cállate un rato. Por el amor de Di...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5469</th>\n",
              "      <td>5617</td>\n",
              "      <td>@user @user @user @user @user Ese conchetumare...</td>\n",
              "      <td>incivilidad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5696d1f4-6b10-4010-90bf-b69c5e115673')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5696d1f4-6b10-4010-90bf-b69c5e115673 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5696d1f4-6b10-4010-90bf-b69c5e115673');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7a34d7b0-b829-49a0-a89f-0d5d17ded3e7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a34d7b0-b829-49a0-a89f-0d5d17ded3e7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7a34d7b0-b829-49a0-a89f-0d5d17ded3e7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1902,\n        \"min\": 2654,\n        \"max\": 7643,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2654,\n          5617,\n          7643\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"@user Iba a comentar que la frase original era re-antigua, que mi vieja se la escuch\\u00f3 a Facundo Cabral, pero busqu\\u00e9 y la frase original es \\\"los mexicanos descienden de los aztecas, los peruanos de los Incas y los argentinos de los barcos\\\". As\\u00ed que Fern\\u00e1ndez la record\\u00f3 como la mierda.\",\n          \"@user @user @user @user @user Ese conchetumare del @user es un cobarde culiao vagoneta y limosnero\",\n          \"@user Dejen de darle tribuna a este comunacho!!!!!\\ud83e\\udd21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clase\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"incivilidad\",\n          \"normal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "rhdWKPEZiMSR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "outputId": "22a4d25c-c1a2-4a34-e0f6-88563d45dc9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "clase\n",
              "incivilidad    5424\n",
              "normal         4280\n",
              "odio           2510\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clase</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>incivilidad</th>\n",
              "      <td>5424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>normal</th>\n",
              "      <td>4280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>odio</th>\n",
              "      <td>2510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "df[\"clase\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLHWoi4TiMSS"
      },
      "source": [
        "### Instalar librerias\n",
        "\n",
        "Debe instalar las siguientes librerías:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "e-AfecWmiMSS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install wordcloud\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi_mJozgiMST"
      },
      "source": [
        "Si lo desea, puede instalar más librería que requiera, pero debe citar su fuente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfqkdt0kiMST"
      },
      "source": [
        "### Importar librerías\n",
        "\n",
        "En esta sección, importamos la liberías necesarias para el correcto desarrollo de esta tarea. Puede utilizar otras librerías que no se en encuentran aquí, pero debe citar su fuente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "I4JcaTc0iMST"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.text import Text\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# importe aquí sus clasificadores\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# word2vec\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from gensim.models.phrases import Phrases, Phraser\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxbSG538iMSU"
      },
      "source": [
        "### Análisis estadístico\n",
        "\n",
        "Para entender como esta compuesto el corpus de texto, y los principales conceptos que aborda, haremos un análisis estadístico de sus principales componentes, para esto se le pide:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_NJtqNuiMSU"
      },
      "source": [
        "#### 1. Tokenizador\n",
        "\n",
        "Como vimos en clases pasadas, el como separar los principales token de una oración no siempre es una tarea fácil. Por lo que para separar los principales token del texto asociado a cada sentimiento se pide que defina un tokenizador, que entregue una lista de los principales tokens. Su tokenizador debe contener al menos tres expresiones regulares, que usted estime conveniente para hacer la separación de los token dentro de la oración, para ello complete le siguiente función:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "mk4uTb07iMSU"
      },
      "outputs": [],
      "source": [
        "def tokenizador(oracion):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gv7CB0giMSV"
      },
      "source": [
        "En el siguiente ejemplo, se muestra un comportamiento esperado de su tokenizador, usando como ejemplo el `word_tokenize` de la librería `nltk`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjJZQe8lXKYX",
        "outputId": "0e63c837-e019-4af9-e16f-af7449ffa722"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "4ibM0v0JiMSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b61184e-1f16-4d42-9c6f-05628a2861c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sara',\n",
              " 'sufrió',\n",
              " 'una',\n",
              " 'caída',\n",
              " 'que',\n",
              " 'ocasionó',\n",
              " 'la',\n",
              " 'pérdida',\n",
              " 'de',\n",
              " 'su',\n",
              " 'embarazo',\n",
              " 'de',\n",
              " '8',\n",
              " 'meses',\n",
              " '.',\n",
              " 'Estuvo',\n",
              " 'presa',\n",
              " 'casi',\n",
              " '10',\n",
              " 'años',\n",
              " 'porque',\n",
              " 'el',\n",
              " 'Estado',\n",
              " 'la',\n",
              " 'acusó',\n",
              " 'de',\n",
              " 'homicidio',\n",
              " 'en',\n",
              " 'un',\n",
              " 'país',\n",
              " 'donde',\n",
              " 'el',\n",
              " 'aborto',\n",
              " 'está',\n",
              " 'radicalmente',\n",
              " 'penalizado',\n",
              " '.',\n",
              " 'Por',\n",
              " 'casos',\n",
              " 'como',\n",
              " 'el',\n",
              " 'de',\n",
              " 'ella',\n",
              " 'y',\n",
              " 'muchas',\n",
              " 'otras',\n",
              " 'es',\n",
              " 'que',\n",
              " 'el',\n",
              " 'aborto',\n",
              " 'debe',\n",
              " 'ser',\n",
              " 'legal',\n",
              " '.',\n",
              " 'https',\n",
              " ':',\n",
              " '//t.co/BVEwo28kwl']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Ejemplo\n",
        "\n",
        "oracion = df['texto'].sample(1).values[0]\n",
        "word_tokenize(oracion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyFsRmFhiMSV"
      },
      "source": [
        "Ahora pruebe su tokenizador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "9GGjvlZ8iMSW"
      },
      "outputs": [],
      "source": [
        "oracion = df['texto'].sample(1).values[0]\n",
        "tokenizador(oracion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x31twODfiMSW"
      },
      "source": [
        "Ahora responda, su tokenizador funciona igual que el provisto por la librería, y si es así explique porque, en caso contrario, indique las causa de porque no."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR7kyQF7iMSW"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h14PvAq-iMSW"
      },
      "source": [
        "#### 2) Crear una lista de tokens.\n",
        "\n",
        "Dado que nos interesa entender cuales son los token que más impacto tienen dentro del corpus de texto provisto, debemos extraerlos del conjunto de entrenamiento. Para esto, guarde en la lista TODOS los token del conjunto de entrenamiento en la lista `tokens`, para separar los tokens de la oraciones utilice su tokenizador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "CWZX3lwhiMSX"
      },
      "outputs": [],
      "source": [
        "tokens = []\n",
        "\n",
        "# Código (recuerde utilizar su tokenizador)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9SKRF7IiMSY"
      },
      "source": [
        "Para asegurarse que guardo correctamente las palabras, extraiga los primeros 10 tokens de la lista, y revise el largo de la lista. Ejecutando la siguiente línea de código, ojo que el largo de la lista `tokens` debe ser cercano o mayor 300000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "td5hq4c4iMSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa83ef2-ac52-4b88-b307-5d8362fe7199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(len(tokens))\n",
        "print(tokens[:11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlH6YZoSiMSY"
      },
      "source": [
        "#### 3) Análisis estadísticos los tokens.\n",
        "\n",
        "Para realizar nuestro análisis utilizaremos las primeras técnicas en el curso:\n",
        "\n",
        "- a) Para estudiar los tokens más frequentes dentro del corpus, cree dos gráfico de frecuencias (ver tutorial 1.2), uno con todos los tokens de la lista, y otro eliminandos las stopwords. ¿Qué puede decir sobre estos gráficos?, ¿Existe alguna diferencia al mantener las stopwords vs a quitarlas de los tokens?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "RT3tJVMSiMSZ"
      },
      "outputs": [],
      "source": [
        "# Grafico 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "xn_RbltQiMSZ"
      },
      "outputs": [],
      "source": [
        "# Grafico 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2pAVxl_iMSa"
      },
      "source": [
        "- b) Dado que siempre es importante, identificar los principales tokens mencionados en un corpus de texto, cree dos wordclouds (ver tutorial 2) sobre los tokens que obtuvo en la parte anterior, uno con stopwords y otro sin ellas. ¿Qué puede decir sobre estos gráficos?, ¿Existe alguna diferencia al mantener las stopwords vs a quitarlas de los tokens?, considerando la parte a) existe alguna diferencia versus las palabras que usted pensó que era más interesantes?, que puede decir al respecto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "SAeRR1YZiMSa"
      },
      "outputs": [],
      "source": [
        "# Grafico 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "4J8AfuINiMSa"
      },
      "outputs": [],
      "source": [
        "# Grafico 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_XtXb8OiMSb"
      },
      "source": [
        "## Crear representaciones de texto\n",
        "\n",
        "Como hemos mencionado en las clases anteriores, los modelos de Machine Learning no son capaces de entender el texto directamente para resolver cualquier tarea. Es vital realizar un paso intermedio, que es buscar un mecanismo que permita traducir el texto a representaciones que puedan ser entendidas por los modelos de ML, y que conserven las propiedades semánticas y sintacticas del lenguaje. Es por esto, que en está sección estudiaremos los métodos de text representation estudiados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_yZoSVGiMSj"
      },
      "source": [
        "- a) El primer método que se les solicita, es crear una representación de Bag of Words o TF-IDF (la que prefieran) utilizando la librería `scikit-learn`. Para esto, puede serle útil revisar el tutorial 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "gpeWWc6kiMSj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_n64dVDiMSk"
      },
      "source": [
        "- b) El segundo método que se les solicita, es crear una representación con word embeddings. Para esto, puede serle útil revisar el tutorial 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "KYhF6Hm3iMSk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKQa25HSiMSk"
      },
      "source": [
        "## Definir clasificadores\n",
        "\n",
        "En esta parte, se procedera a entrenar, los clasificadores por cada representación de texto, creada en la parte anterior, para esto usted debe:\n",
        "\n",
        "Se sugiere revisar el tutorial 4, para recordar como utilizar los clasificadores de `scikit-learn`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK8o4yBBiMSk"
      },
      "source": [
        "1. Definir los datos y las etiquetas de entrenamiento y testeo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "5-nGf6z9iMSk"
      },
      "outputs": [],
      "source": [
        "#separar df en entrenamiento y testing\n",
        "X_train = ...\n",
        "y_train = ...\n",
        "\n",
        "X_test = ...\n",
        "y_test = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZXAlliHiMSk"
      },
      "source": [
        "Una pregunta, que podría hacerse: ¿Es necesario separar el dataset en training y testing, usando alguna función de `scikit-learn` en este caso? Fundamente:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUE_5S4hiMSl"
      },
      "source": [
        "2. Definir al menos dos clasificadores por representación:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxKJODgIiMSl"
      },
      "source": [
        "#### Bag of Words o TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "CwR3ZnN0iMSl"
      },
      "outputs": [],
      "source": [
        "clf1 = ...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gDFbFKTDiMSl"
      },
      "outputs": [],
      "source": [
        "clf2 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gquhv9F7iMSl"
      },
      "source": [
        "#### Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "ACUnu6LUiMSl"
      },
      "outputs": [],
      "source": [
        "clf3 = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "nDdqCVCKiMSl"
      },
      "outputs": [],
      "source": [
        "clf4 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tyvfoYYiMSl"
      },
      "source": [
        "Para esta sección pueden utilizar cualquier clasificadores que estimen conveniente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvUDccA9iMSm"
      },
      "source": [
        "3. Entrenar cada uno de los clasificadores desarrollados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "g-pTSK9hiMSm"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento classificador 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Ip6clmmziMSm"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento classificador 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "UO1K16xdiMSm"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento classificador 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "KEfGBGlxiMSn"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento classificador 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy5zMy26iMSn"
      },
      "source": [
        "### Evaluar los clasificadores.\n",
        "\n",
        "En esta sección, se espera que entregue la matriz de confusión y el reporte de clasificación de los clasificadores en la sección pasada. Por lo que seria útil estudiar las funciones `confusion_matrix` y `classification_report` de `scikit-lear`. Podrá encontrar un ejemplo en el tutorial 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "YIjer8z_iMSn"
      },
      "outputs": [],
      "source": [
        "# Informe de evaluación clasificador 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "XV26PdMviMSn"
      },
      "outputs": [],
      "source": [
        "# Informe de evaluación clasificador 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "i8VkoD_AiMSn"
      },
      "outputs": [],
      "source": [
        "# Informe de evaluación clasificador 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Bix6uD2OiMSo"
      },
      "outputs": [],
      "source": [
        "# Informe de evaluación clasificador 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjNWyooviMSo"
      },
      "source": [
        "Finalmente, ¿Qué pude decir del rendimiento de todos los clasificadores?, ¿Cree que alguna representación pudo resolver mejor la tarea? Jusfique, se espera que de un análsis para cada uno de los 4 clasificadores, identificado sus aciertos y fallas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}